# Git Issue Agent - OpenAI configuration
#
# Uses OpenAI for LLM inference.
# Prerequisite: Create the Kubernetes secret with your API key:
#   kubectl create secret generic openai-secret -n team1 \
#     --from-literal=apikey="<YOUR_OPENAI_API_KEY>"

# LLM configuration
TASK_MODEL_ID=gpt-4.1-nano
LLM_API_KEY='{"valueFrom": {"secretKeyRef": {"name": "openai-secret", "key": "apikey"}}}'
OPENAI_API_KEY='{"valueFrom": {"secretKeyRef": {"name": "openai-secret", "key": "apikey"}}}'

# Agent service
SERVICE_PORT=8000
LOG_LEVEL=DEBUG

# MCP Tool endpoint
MCP_URL=http://github-tool-mcp:9090/mcp

# Keycloak / AuthBridge token settings
JWKS_URI=http://keycloak-service.keycloak.svc:8080/realms/demo/protocol/openid-connect/certs
TOKEN_URL=http://keycloak-service.keycloak.svc:8080/realms/demo/protocol/openid-connect/token
TARGET_SCOPES=github-full-access github-partial-access
